import torch
import torch.nn as nn
import torch.nn.functional as F
import torch_geometric.nn as pyg_nn
from torchvision.models import resnet18,  ResNet18_Weights
from torch_geometric.data import Data, Batch

from easydict import EasyDict

from DHDN.builder import MODEL

#################################################################################80
## Dynamic
# 1.å¼•å…¥å¯å˜è¶…è¾¹çš„èŠ‚ç‚¹æ•°ï¼Œè®¾ç½®æœ€å¤§å€¼å³å¯
# 2.ä¸€å¾‹å¼•å…¥æ¢¯åº¦è£å‰ª: l2, max_norm=1
# 3.å¼•å…¥åŠ¨æ€æŸå¤±

@MODEL.register_module
class DHDN_Dynamic(nn.Module):
    def __init__(self, **cfg):
        # num_joints=19, num_features=2, num_patterns=5, hidden_dim=64, image_size_h=256, image_size_w=256):
        super(DHDN_Dynamic, self).__init__()

        self._preset_cfg   = cfg['PRESET']
        self.num_joints     = self._preset_cfg['NUM_JOINTS']
        self.image_size_h = self._preset_cfg['HEATMAP_SIZE'][0]
        self.image_size_w = self._preset_cfg['HEATMAP_SIZE'][1]
        self.num_patterns = self._preset_cfg['HEATMAP_SIZE'][1]

        self.num_nodes_per_hyperedge = cfg['NUM_NODES_PER_HYPEREDGE']
        self.num_patterns = cfg['NUM_PATTERNS'] # the number of latent patterns
        self.num_features = cfg['NUM_FEATURES'] # è¾“å…¥çš„åæ ‡æ˜¯äºŒç»´çš„x,y,æ•…æ­¤ä¸º2
        self.hidden_dim = cfg['HIDDEN_DIM'] # hidden_dim æ˜¯æ¨¡å‹ä¸­éšè—å±‚ç‰¹å¾çš„ç»´åº¦ï¼Œè¡¨ç¤ºæ¯ä¸ªèŠ‚ç‚¹ï¼ˆæ ‡å¿—ç‚¹ï¼‰æˆ–è¶…è¾¹çš„ç‰¹å¾å‘é‡é•¿åº¦ã€‚å®ƒæ˜¯è¶…å›¾ç‰¹å¾H å’Œå›¾åƒç‰¹å¾çš„ç»´åº¦ï¼Œä¹Ÿæ˜¯ç½‘ç»œå†…éƒ¨è¡¨ç¤ºçš„å®½åº¦ã€‚

        # CNN for image features (é€‚é… 3 é€šé“è¾“å…¥)
        self.cnn = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)
        self.cnn.fc = nn.Linear(512, self.hidden_dim)  # è¾“å‡º hidden_dim

        # DHE: Dynamic Hypergraph Evolution
        self.hyperedge_init = nn.Linear(self.num_features, self.hidden_dim)  # è¾“å…¥åæ ‡ [x, y] æ˜ å°„åˆ°é«˜ç»´ç©ºé—´
        self.hyper_gnn = nn.ModuleList([
            pyg_nn.HypergraphConv(self.hidden_dim, self.hidden_dim) for _ in range(3)  # 3 å±‚è¶…å›¾å·ç§¯
        ])
        self.hyper_gnn_norms = nn.ModuleList([
            nn.LayerNorm(self.hidden_dim) for _ in range(3)  # æ¯å±‚åŠ å½’ä¸€åŒ–
        ])
        self.attention = nn.MultiheadAttention(self.hidden_dim, num_heads=4) # å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶

        # DPE: Disentangled Pattern Extractor (VAE)
        # ç›¸å½“äºæ„å»ºäº†ä¸€ä¸ªæ½œåœ¨çš„æ¨¡å¼ç©ºé—´
        self.encoder = nn.Sequential(
            nn.Linear(self.num_joints * self.hidden_dim, 256),
            nn.ReLU(),
            nn.Linear(256, self.num_patterns * 2)  # mu + log_var, è‡ªåˆ¶çš„VAEï¼Œè¾“å‡ºçš„æ˜¯muå’Œlog_varï¼Œ
        )
        self.decoder = nn.Linear(self.num_patterns, self.num_joints * self.hidden_dim) # è¾“å…¥æ˜¯é‡‡æ ·çš„Z

        # GRM: Generative Refinement Module
        self.refiner = nn.Sequential(
            nn.Linear(self.num_joints * self.hidden_dim, 256),
            nn.ReLU(),
            nn.Linear(256, self.num_joints * 2)  # ä»é«˜çº¬ç©ºé—´å°†ç‰¹å¾æ˜ å°„åˆ° [19 * 2]
        )

    def extract_image_features(self, images, points):
        # images: [batch, 3, H, W], points: [batch, 19, 2]
        batch_size = images.size(0)
        height, width = images.size(2), images.size(3)  # H, W
        patches = []
        for b in range(batch_size):
            for p in points[b]:  # p æ˜¯å½’ä¸€åŒ–åæ ‡ [-0.5, 0.5]
                # è½¬æ¢åˆ°å›¾åƒåæ ‡ [0, W] å’Œ [0, H]
                x = int((p[0] + 0.5) * self.image_size_w)
                y = int((p[1] + 0.5) * self.image_size_h)
                # è®¡ç®—è£å‰ªè¾¹ç•Œå¹¶é™åˆ¶åœ¨å›¾åƒèŒƒå›´å†…
                patch_size_half = self.image_size_w//32
                x_min = max(0, x - patch_size_half)
                x_max = min(width, x + patch_size_half)
                y_min = max(0, y - patch_size_half)
                y_max = min(height, y + patch_size_half)
                # ç¡®ä¿æœ€å°å°ºå¯¸
                if x_max <= x_min:
                    x_min = x_max - 1
                if y_max <= y_min:
                    y_min = y_max - 1
                patch = images[b:b+1, :, y_min:y_max, x_min:x_max]
                # è°ƒè¯•ï¼šæ‰“å° patch å°ºå¯¸
                # print(f"Patch shape: {patch.shape}, x: [{x_min}, {x_max}], y: [{y_min}, {y_max}]")
                patch = F.interpolate(patch, size=(224, 224), mode='bilinear')
                patches.append(patch)
        patches = torch.cat(patches, dim=0)  # [batch * 19, 3, 224, 224]
        features = self.cnn(patches)  # [batch * 19, hidden_dim]
        return features.view(batch_size, self.num_joints, -1)  # [batch_size, num_joints, hidden_dim]
    
    def build_variable_hyperedges_batch(self, points, img_features):
        """Build hyperedges with variable sizes for each batch sample."""
        max_k = self.num_nodes_per_hyperedge
        batch_size = points.size(0)
        device = points.device
        edge_indices = []

        for b in range(batch_size):
            # è®¡ç®—è·ç¦»ï¼ˆé€æ ·æœ¬éš”ç¦»ï¼‰
            coord_dist = torch.cdist(points[b:b+1], points[b:b+1]).squeeze(0)  # [19, 19]
            feat_dist = torch.cdist(img_features[b:b+1], img_features[b:b+1]).squeeze(0)  # [19, 19]
            combined_dist = 0.5 * coord_dist + 0.5 * feat_dist  # [19, 19]

            # è½¬æ¢ä¸ºæ³¨æ„åŠ›åˆ†æ•°ï¼ˆåŸºäºè·ç¦»çš„è´Ÿå€¼ï¼‰
            attn_scores = torch.softmax(-combined_dist, dim=-1)  # [19, 19]

            # åŠ¨æ€æ„å»ºè¶…è¾¹
            edge_list = []
            for i in range(self.num_joints):
                k = torch.randint(2, max_k + 1, (1,), device=device).item()  # éšæœºé€‰æ‹©è¶…è¾¹å¤§å° [2, max_k]
                _, indices = attn_scores[i].topk(k, largest=True)  # [k]ï¼Œé€‰æ‹© k ä¸ªæœ€è¿‘é‚»
                edge_list.append(torch.cat([
                    torch.full((k,), i, dtype=torch.long, device=device),  # ä¸­å¿ƒèŠ‚ç‚¹
                    indices  # é‚»å±…èŠ‚ç‚¹
                ]))

            # æ‹¼æ¥ä¸ºè¶…è¾¹ç´¢å¼•
            edge_index_b = torch.cat(edge_list, dim=0).T  # [2, total_edges_b]ï¼Œtotal_edges_b æ˜¯å¯å˜çš„
            edge_indices.append(edge_index_b)

        return edge_indices  # List of [2, total_edges_b]ï¼Œæ¯ä¸ªæ ·æœ¬çš„ total_edges_b å¯å˜

    def reparameterize(self, mu, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mu + eps * std # éšæœºé‡‡æ · z
    
    def _initialize(self):
        pass

    def forward(self, img, target_uv):
        # img: [batch, 3, H, W], target_uv: [batch, 19 * 2]
        batch_size = img.size(0)
        points = target_uv.view(batch_size, self.num_joints, 2)  # [batch, 19, 2]

        # Extract image features
        img_features = self.extract_image_features(img, points) # [batch_size, num_joints, hidden_dim], æå–å¹¶æ˜ å°„ä¸º hidden_dim

        # DHE: Dynamic Hypergraph Evolution (Batch)
        ## h = self.hyperedge_init(points)  # [batch, 19, hidden_dim], å…³äºèŠ‚ç‚¹çš„è¶…å›¾
        ## edge_index = self.build_hyperedges_batch(points, img_features) # [2, batch * 19 * 3]
        ## h = self.hyper_gnn(h.view(-1, h.size(-1)), edge_index)  # å°†hçš„ç»´åº¦é‡ç»„ä¸º2ç»´ï¼Œç¬¬ä¸€ä¸ªç»´åº¦è®¡ç®—ï¼Œç¬¬äºŒä¸ªç»´åº¦ä¸ºh.size(-1)ï¼Œå³ hidden_dimï¼Œå¾—åˆ°[batch * 19, hidden_dim]

        h = self.hyperedge_init(points)  # [batch, 19, hidden_dim]
        # é€æ ·æœ¬æ„å»ºè¶…å›¾
        edge_indices = self.build_variable_hyperedges_batch(points, img_features)  # List of [2, 19 * 3]
        data_list = [Data(x=h[b], edge_index=edge_indices[b]) for b in range(batch_size)]
        batch_data = Batch.from_data_list(data_list)  # è‡ªåŠ¨å¤„ç†æ‰¹é‡
        # è¶…å›¾å·ç§¯
        h = self.hyper_gnn(batch_data.x, batch_data.edge_index)  # [batch * 19, hidden_dim]

        # è®°å½•è¶…å›¾ç‰¹å¾å±‚
        h_layers = [batch_data.x]  # åˆå§‹ç‰¹å¾ [batch * 19, hidden_dim]
        h = batch_data.x
        for gnn, norm in zip(self.hyper_gnn, self.hyper_gnn_norms):
            h = gnn(h, batch_data.edge_index)  # [batch * 19, hidden_dim]
            h = norm(F.relu(h))  # æ·»åŠ éçº¿æ€§æ¿€æ´»å’Œå½’ä¸€åŒ–
            h_layers.append(h)  # è®°å½•æ¯å±‚è¾“å‡º

        h = h.view(batch_size, self.num_joints, -1) # [batch, 19, hidden_dim]
        h, _ = self.attention(h, h, h) # self.attetnion


        # DPE: Disentangled Pattern Extractor
        h_flat = h.view(batch_size, -1)  # [batch, 19 * hidden_dim]
        z_params = self.encoder(h_flat) # [batch,  2 * self.num_patterns] (mus and log_vars)
        mu, log_var = z_params[:, :self.num_patterns], z_params[:, self.num_patterns:] # è¯»å–ï¼Œå‰å‡ ä¸ªæ˜¯muï¼Œåå‡ ä¸ªæ˜¯log_vars
        z = self.reparameterize(mu, log_var)  # æ ¹æ®muå’Œlog_varé‡é‡‡æ ·z [batch, num_patterns]

        # GRM: Generative Refinement
        h_recon = self.decoder(z)  # [batch, 19 * hidden_dim], reconstructed hidden representation from a pattern z
        h_recon = h_recon.view(batch_size, self.num_joints, -1) # [batch, 19, hidden_dim]
        points_refined = self.refiner(h_recon.view(batch_size, -1))  # map from hidden space to x, y [batch, 19 * 2]
        points_refined = points_refined.view(batch_size, self.num_joints, 2) # [batchsize, num_joints, 2], of course in [-0.5, 0.5]

        output = EasyDict(
            pred_pts=points_refined, # [batchsize, num_joints, 2]
            mu=mu, # [batch, num_patterns] 
            log_var=log_var, # mu, log_var å«ä¹‰ï¼šVAE çš„å‡å€¼å’Œå¯¹æ•°æ–¹å·®ï¼Œç”¨äºç”Ÿæˆğ‘, [batch, num_patterns]ï¼ˆä¾‹å¦‚ [batch, num_patterns]ï¼‰ã€‚
            z=z, # [batchsize, num_patterns]
            h_layers=h_layers,  # æ–°å¢ï¼šè¶…å›¾ç‰¹å¾å±‚
            heatmap=None # [batchsize, num_joints, hm_height, hm_width]
        )

        return output
        # points_refined [batchsize, num_joints, 2]



# å¦‚ä½•ä½¿ç”¨æ¨¡å‹ï¼šåˆå§‹åŒ–æ¨¡å‹
# model = DHDN(num_joints=19, num_features=2, num_patterns=5, hidden_dim=64,
#            image_size_h=256, image_size_w=256).cuda()