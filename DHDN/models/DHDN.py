import torch
import torch.nn as nn
import torch.nn.functional as F
import torch_geometric.nn as pyg_nn
from torchvision.models import resnet18,  ResNet18_Weights
from torch_geometric.data import Data, Batch

from easydict import EasyDict

from DHDN.builder import MODEL

@MODEL.register_module
class DHDN(nn.Module):
    def __init__(self, **cfg):
        # num_joints=19, num_features=2, num_patterns=5, hidden_dim=64, image_size_h=256, image_size_w=256):
        super(DHDN, self).__init__()

        self._preset_cfg   = cfg['PRESET']
        self.num_joints     = self._preset_cfg['NUM_JOINTS']
        self.image_size_h = self._preset_cfg['HEATMAP_SIZE'][0]
        self.image_size_w = self._preset_cfg['HEATMAP_SIZE'][1]
        self.num_patterns = self._preset_cfg['HEATMAP_SIZE'][1]

        self.num_nodes_per_hyperedge = cfg['NUM_NODES_PER_HYPEREDGE']
        self.num_patterns = cfg['NUM_PATTERNS'] # the number of latent patterns
        self.num_features = cfg['NUM_FEATURES'] # è¾“å…¥çš„åæ ‡æ˜¯äºŒç»´çš„x,y,æ•…æ­¤ä¸º2
        self.hidden_dim = cfg['HIDDEN_DIM'] # hidden_dim æ˜¯æ¨¡å‹ä¸­éšè—å±‚ç‰¹å¾çš„ç»´åº¦ï¼Œè¡¨ç¤ºæ¯ä¸ªèŠ‚ç‚¹ï¼ˆæ ‡å¿—ç‚¹ï¼‰æˆ–è¶…è¾¹çš„ç‰¹å¾å‘é‡é•¿åº¦ã€‚å®ƒæ˜¯è¶…å›¾ç‰¹å¾H å’Œå›¾åƒç‰¹å¾çš„ç»´åº¦ï¼Œä¹Ÿæ˜¯ç½‘ç»œå†…éƒ¨è¡¨ç¤ºçš„å®½åº¦ã€‚

        # CNN for image features (é€‚é… 3 é€šé“è¾“å…¥)
        self.cnn = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)
        self.cnn.fc = nn.Linear(512, self.hidden_dim)  # è¾“å‡º hidden_dim

        # DHE: Dynamic Hypergraph Evolution
        self.hyperedge_init = nn.Linear(self.num_features, self.hidden_dim)  # è¾“å…¥åæ ‡ [x, y] æ˜ å°„åˆ°é«˜ç»´ç©ºé—´
        self.hyper_gnn = pyg_nn.HypergraphConv(self.hidden_dim, self.hidden_dim) # è¶…å›¾å·ç§¯ï¼Œåªæ˜¯æ›´æ–°ï¼Œè€Œä¸æ”¹å˜ç»´åº¦ï¼Œå®Œå…¨åœ°çº¿æ€§æ˜ å°„, éœ€è¦æ‰‹åŠ¨æ·»åŠ æ¿€æ´»å±‚
        self.attention = nn.MultiheadAttention(self.hidden_dim, num_heads=4) # å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶

        # DPE: Disentangled Pattern Extractor (VAE)
        # ç›¸å½“äºæ„å»ºäº†ä¸€ä¸ªæ½œåœ¨çš„æ¨¡å¼ç©ºé—´
        self.encoder = nn.Sequential(
            nn.Linear(self.num_joints * self.hidden_dim, 256),
            nn.ReLU(),
            nn.Linear(256, self.num_patterns * 2)  # mu + log_var, è‡ªåˆ¶çš„VAEï¼Œè¾“å‡ºçš„æ˜¯muå’Œlog_varï¼Œ
        )
        self.decoder = nn.Linear(self.num_patterns, self.num_joints * self.hidden_dim) # è¾“å…¥æ˜¯é‡‡æ ·çš„Z

        # GRM: Generative Refinement Module
        self.refiner = nn.Sequential(
            nn.Linear(self.num_joints * self.hidden_dim, 256),
            nn.ReLU(),
            nn.Linear(256, self.num_joints * 2)  # ä»é«˜çº¬ç©ºé—´å°†ç‰¹å¾æ˜ å°„åˆ° [19 * 2]
        )

    def extract_image_features(self, images, points):
        # images: [batch, 3, H, W], points: [batch, 19, 2]
        batch_size = images.size(0)
        height, width = images.size(2), images.size(3)  # H, W
        patches = []
        for b in range(batch_size):
            for p in points[b]:  # p æ˜¯å½’ä¸€åŒ–åæ ‡ [-0.5, 0.5]
                # è½¬æ¢åˆ°å›¾åƒåæ ‡ [0, W] å’Œ [0, H]
                x = int((p[0] + 0.5) * self.image_size_w)
                y = int((p[1] + 0.5) * self.image_size_h)
                # è®¡ç®—è£å‰ªè¾¹ç•Œå¹¶é™åˆ¶åœ¨å›¾åƒèŒƒå›´å†…
                patch_size_half = self.image_size_w//32
                x_min = max(0, x - patch_size_half)
                x_max = min(width, x + patch_size_half)
                y_min = max(0, y - patch_size_half)
                y_max = min(height, y + patch_size_half)
                # ç¡®ä¿æœ€å°å°ºå¯¸
                if x_max <= x_min:
                    x_min = x_max - 1
                if y_max <= y_min:
                    y_min = y_max - 1
                patch = images[b:b+1, :, y_min:y_max, x_min:x_max]
                # è°ƒè¯•ï¼šæ‰“å° patch å°ºå¯¸
                # print(f"Patch shape: {patch.shape}, x: [{x_min}, {x_max}], y: [{y_min}, {y_max}]")
                patch = F.interpolate(patch, size=(224, 224), mode='bilinear')
                patches.append(patch)
        patches = torch.cat(patches, dim=0)  # [batch * 19, 3, 224, 224]
        features = self.cnn(patches)  # [batch * 19, hidden_dim]
        return features.view(batch_size, self.num_joints, -1)  # [batch_size, num_joints, hidden_dim]
    
    def extract_image_features_1(self, images, points):
        # images: [batch, 3, H, W], points: [batch, 19, 2]
        batch_size = images.size(0)
        patches = []
        for b in range(batch_size):
            for p in points[b]:  # p æ˜¯å½’ä¸€åŒ–åæ ‡ [-0.5, 0.5]
                # è½¬æ¢åˆ°å›¾åƒåæ ‡ [0, W] å’Œ [0, H]
                x = int((p[0] + 0.5) * self.image_size_w)
                y = int((p[1] + 0.5) * self.image_size_h)
                patch = images[b:b+1, :, max(0, y-16):y+16, max(0, x-16):x+16] # åœ¨å¯¹åº”çš„å›¾é‡Œæå–16x16 patch

                patch = F.interpolate(patch, size=(224, 224), mode='bilinear')  # ResNet éœ€è¦ 224x224
                patches.append(patch)
        patches = torch.cat(patches, dim=0)  # [batch * 19, 3, 224, 224]
        features = self.cnn(patches)  # [batch * 19, hidden_dim], å°† CNN å¾—åˆ°çš„ patch æå–ç‰¹å¾ä¸ºhidden_dim
        return features.view(batch_size, self.num_joints, -1) # [batch_size, num_joints, hidden_dim]

    def build_hyperedges(self, points, img_features):
        # points: [batch, 19, 2], img_features: [batch, 19, hidden_dim]
        coord_dist = torch.cdist(points, points)  # [batch, 19, 19], è®¡ç®—ä¸¤ä¸ªå¼ é‡ä¹‹é—´çš„æˆå¯¹è·ç¦»ï¼ˆpairwise distanceï¼‰, é€šè¿‡è®¾ç½®pæ¥ç¡®å®šè·ç¦»ç±»å‹ã€‚é»˜è®¤ä¸ºæ¬§æ°è·ç¦»ï¼ŒåŒ…æ‹¬ä¸€ä¸ªèŠ‚ç‚¹ä¸è‡ªèº«çš„è·ç¦»
        feat_dist = torch.cdist(img_features, img_features)  # [batch, 19, 19] 
        combined_dist = 0.5 * coord_dist + 0.5 * feat_dist # [batch, 19, 19] 
        _, indices = combined_dist.topk(k=self.num_nodes_per_hyperedge, dim=-1, largest=False) # è¿”å›æŒ‡å®šç»´åº¦ä¸Šæœ€å°ï¼ˆæˆ–æœ€å¤§ï¼‰çš„ k ä¸ªå€¼å’Œå®ƒä»¬çš„ç´¢å¼•, æœ€è¿‘é‚»è·å–
        edge_index = torch.cat([torch.arange(self.num_joints).repeat_interleave(self.num_nodes_per_hyperedge).unsqueeze(0),
                                indices.view(-1).unsqueeze(0)], dim=0)
        # ç¬¬ä¸€è¡Œï¼š[1, batch * 19 * 3]ï¼ˆä¸­å¿ƒèŠ‚ç‚¹ï¼‰ã€‚[0, 0, 0, 1, 1, 1, ..., 18, 18, 18]ï¼ˆ57 ä¸ªå…ƒç´ ï¼‰ã€‚
        # ç¬¬äºŒè¡Œï¼š[1, batch * 19 * 3]ï¼ˆé‚»å±…èŠ‚ç‚¹ï¼‰ã€‚[2, 5, 7, 0, 3, 4, ..., ...]ï¼ˆ57 ä¸ªå…ƒç´ ï¼‰ã€‚
        # åœ¨ edge_index ä¸­ï¼Œè¶…è¾¹è¢«æ‹†åˆ†ä¸ºå¤šæ¡äºŒå…ƒè¾¹ï¼ˆä¾‹å¦‚ [0, 2], [0, 5], [0, 7]ï¼‰ï¼Œä½† HypergraphConv ä¼šå°†å…¶è§†ä¸ºä¸€ä¸ªæ•´ä½“è¶…è¾¹ã€‚
        return edge_index # [2, num_joints * self.num_nodes_per_hyperedge]
    
    def build_hyperedges_batch(self, points, img_features):
        batch_size = points.size(0)
        edge_indices = []
        for b in range(batch_size):
            # æ¯ä¸ªæ ·æœ¬ç‹¬ç«‹è®¡ç®—è·ç¦»
            coord_dist = torch.cdist(points[b:b+1], points[b:b+1]).squeeze(0)  # [19, 19]
            feat_dist = torch.cdist(img_features[b:b+1], img_features[b:b+1]).squeeze(0)  # [19, 19]
            combined_dist = 0.5 * coord_dist + 0.5 * feat_dist  # [19, 19]
            _, indices = combined_dist.topk(k=self.num_nodes_per_hyperedge, dim=-1, largest=False)  # [19, 3]
            edge_index_b = torch.cat([torch.arange(self.num_joints).repeat_interleave(self.num_nodes_per_hyperedge).unsqueeze(0),
                                      indices.view(-1).unsqueeze(0)], dim=0)  # [2, 19 * 3]
            edge_indices.append(edge_index_b)
        # æŒ‰æ‰¹é‡åç§»ç´¢å¼•
        edge_index = torch.cat([e + b * self.num_joints for b, e in enumerate(edge_indices)], dim=1) #å°†ç´¢å¼•å€¼åŠ ä¸Šåç§»ï¼Œç¡®ä¿æ¯ä¸ªæ ·æœ¬çš„ç‚¹ç´¢å¼•æ˜¯ç‹¬ç«‹çš„ã€‚
        return edge_index  # [2, batch * 19 * 3]
    
    def build_hyperedges_batchnew(self, points, img_features):
        """ deal with the batch problem for hypergraph """
        batch_size = points.size(0)
        device = points.device
        edge_indices = []
        for b in range(batch_size):
            coord_dist = torch.cdist(points[b:b+1], points[b:b+1]).squeeze(0)  # [19, 19]
            feat_dist = torch.cdist(img_features[b:b+1], img_features[b:b+1]).squeeze(0)  # [19, 19]
            combined_dist = 0.5 * coord_dist + 0.5 * feat_dist
            _, indices = combined_dist.topk(k=self.num_nodes_per_hyperedge, dim=-1, largest=False)  # [19, 3]
            edge_index_b = torch.cat([torch.arange(self.num_joints, device=device).repeat_interleave(self.num_nodes_per_hyperedge).unsqueeze(0),
                                      indices.view(-1).unsqueeze(0)], dim=0)  # [2, 19 * 3]
            edge_indices.append(edge_index_b)
        return edge_indices  # List of [2, 19 * 3]

    def reparameterize(self, mu, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mu + eps * std # éšæœºé‡‡æ · z
    
    def _initialize(self):
        pass

    def forward(self, img, target_uv):
        # img: [batch, 3, H, W], target_uv: [batch, 19 * 2]
        batch_size = img.size(0)
        points = target_uv.view(batch_size, self.num_joints, 2)  # [batch, 19, 2]

        # Extract image features
        img_features = self.extract_image_features(img, points) # [batch_size, num_joints, hidden_dim], æå–å¹¶æ˜ å°„ä¸º hidden_dim

        # DHE: Dynamic Hypergraph Evolution (Batch)
        ## h = self.hyperedge_init(points)  # [batch, 19, hidden_dim], å…³äºèŠ‚ç‚¹çš„è¶…å›¾
        ## edge_index = self.build_hyperedges_batch(points, img_features) # [2, batch * 19 * 3]
        ## h = self.hyper_gnn(h.view(-1, h.size(-1)), edge_index)  # å°†hçš„ç»´åº¦é‡ç»„ä¸º2ç»´ï¼Œç¬¬ä¸€ä¸ªç»´åº¦è®¡ç®—ï¼Œç¬¬äºŒä¸ªç»´åº¦ä¸ºh.size(-1)ï¼Œå³ hidden_dimï¼Œå¾—åˆ°[batch * 19, hidden_dim]

        h = self.hyperedge_init(points)  # [batch, 19, hidden_dim]
        # é€æ ·æœ¬æ„å»ºè¶…å›¾
        edge_indices = self.build_hyperedges_batchnew(points, img_features)  # List of [2, 19 * 3]
        data_list = [Data(x=h[b], edge_index=edge_indices[b]) for b in range(batch_size)]
        batch_data = Batch.from_data_list(data_list)  # è‡ªåŠ¨å¤„ç†æ‰¹é‡
        # è¶…å›¾å·ç§¯
        h = self.hyper_gnn(batch_data.x, batch_data.edge_index)  # [batch * 19, hidden_dim]
        h = h.view(batch_size, self.num_joints, -1) # [batch, 19, hidden_dim]
        h, _ = self.attention(h, h, h) # self.attetnion


        # DPE: Disentangled Pattern Extractor
        h_flat = h.view(batch_size, -1)  # [batch, 19 * hidden_dim]
        z_params = self.encoder(h_flat) # [batch,  2 * self.num_patterns] (mus and log_vars)
        mu, log_var = z_params[:, :self.num_patterns], z_params[:, self.num_patterns:] # è¯»å–ï¼Œå‰å‡ ä¸ªæ˜¯muï¼Œåå‡ ä¸ªæ˜¯log_vars
        z = self.reparameterize(mu, log_var)  # æ ¹æ®muå’Œlog_varé‡é‡‡æ ·z [batch, num_patterns]

        # GRM: Generative Refinement
        h_recon = self.decoder(z)  # [batch, 19 * hidden_dim], reconstructed hidden representation from a pattern z
        h_recon = h_recon.view(batch_size, self.num_joints, -1) # [batch, 19, hidden_dim]
        points_refined = self.refiner(h_recon.view(batch_size, -1))  # map from hidden space to x, y [batch, 19 * 2]
        points_refined = points_refined.view(batch_size, self.num_joints, 2) # [batchsize, num_joints, 2], of course in [-0.5, 0.5]

        output = EasyDict(
            pred_pts=points_refined, # [batchsize, num_joints, 2]
            mu=mu, # [batch, num_patterns] 
            log_var=log_var, # mu, log_var å«ä¹‰ï¼šVAE çš„å‡å€¼å’Œå¯¹æ•°æ–¹å·®ï¼Œç”¨äºç”Ÿæˆğ‘, [batch, num_patterns]ï¼ˆä¾‹å¦‚ [batch, num_patterns]ï¼‰ã€‚
            z=z, # [batchsize, num_patterns]
            heatmap=None # [batchsize, num_joints, hm_height, hm_width]
        )

        return output
        # points_refined [batchsize, num_joints, 2]



# å¦‚ä½•ä½¿ç”¨æ¨¡å‹ï¼šåˆå§‹åŒ–æ¨¡å‹
# model = DHDN(num_joints=19, num_features=2, num_patterns=5, hidden_dim=64,
#            image_size_h=256, image_size_w=256).cuda()